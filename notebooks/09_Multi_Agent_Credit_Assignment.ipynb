{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 09: Multi-Agent Credit Assignment\n\n## Learning Objectives\n- Implement exact and approximate Shapley values\n- Localize errors in agent traces\n- Assign per-agent training signals\n- Implement AT-GRPO advantages\n- Visualize credit distribution"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Credit Assignment Problem\n\n**Scenario:** Solver\u2192Critic\u2192Reviser pipeline gives wrong answer.\n\n**Question:** Which agent is responsible?\n\n**Shapley Value** gives agent $i$'s *average marginal contribution*:\n$$\\varphi_i(v) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!} \\left[v(S \\cup \\{i\\}) - v(S)\\right]$$\n\nProperties: Efficiency (credits sum to outcome), Symmetry, Dummy axiom, Linearity."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# !pip install torch matplotlib"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '..')\nimport torch\nimport matplotlib.pyplot as plt\nprint('Ready!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Exact Shapley Values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.credit_assignment.shapley import exact_shapley_values, ShapleyCalculator\n\nagents = ['solver', 'critic', 'reviser']\n\n# Value function: solver is most important, critic adds value, reviser helps with correction\ndef coalition_value(S):\n    if 'solver' not in S: return 0.0\n    if len(S) == 1: return 0.4  # solver alone = 40% accuracy\n    if 'critic' in S and 'reviser' in S: return 1.0  # full team\n    if 'critic' in S: return 0.7  # solver + critic\n    if 'reviser' in S: return 0.6  # solver + reviser\n    return 0.4\n\nshapley = exact_shapley_values(agents, coalition_value)\nprint('Exact Shapley Values:')\nfor a, v in shapley.items():\n    print(f'  {a:10s}: {v:.4f}')\nprint(f'\\nSum of Shapley values: {sum(shapley.values()):.4f}')\nprint(f'v(all agents) = {coalition_value(frozenset(agents)):.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Visualize Shapley Values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.evaluation.visualization import plot_agent_contributions\nfig = plot_agent_contributions(shapley, title='Shapley Value Credit Attribution')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Error Localization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.credit_assignment.error_localization import ErrorLocalizer\n\n# Scenario: solver makes error, critic catches it, reviser fixes it\ntrace = [\n    {'agent_id': 'solver_0', 'role': 'solver',\n     'content': 'Step 1: 45 + 18 = 63. The answer is: 63'},  # WRONG\n    {'agent_id': 'critic_0', 'role': 'critic',\n     'content': 'VERDICT: INCORRECT \u2014 should subtract not add'},\n    {'agent_id': 'reviser_0', 'role': 'reviser',\n     'content': 'Step 1: 45 - 18 = 27. The answer is: 27'},  # CORRECT\n]\n\nlocalizer = ErrorLocalizer(ground_truth=27.0)\nreport = localizer.get_report(trace, final_correct=True)\nprint('Error Localization Report:')\nfor k, v in report.items():\n    print(f'  {k}: {v}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: AT-GRPO Advantages"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.credit_assignment.at_grpo import ATGRPOTrainer, ATGRPOConfig\n\nagent_rewards = {'solver': 0.3, 'critic': 0.8, 'reviser': 1.0}\nturn_rewards  = {\n    'solver':  [0.1, 0.2, 0.3],\n    'critic':  [0.5, 0.9, 0.8],\n    'reviser': [0.7, 0.9, 1.0],\n}\ntrainer = ATGRPOTrainer(agents=[], config=ATGRPOConfig(agent_weight=0.5))\nadvantages = trainer.compute_combined_advantages(agent_rewards, turn_rewards)\nprint('AT-GRPO Combined Advantages:')\nfor agent, adv in advantages.items():\n    print(f'  {agent}: {[round(a, 3) for a in adv.tolist()]}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Credit Heatmap"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.evaluation.visualization import plot_credit_heatmap\nmatrix = [[0.8, 0.6, 0.9], [-0.5, 0.4, 0.5], [0.2, 0.7, 0.9]]\nfig = plot_credit_heatmap(\n    matrix,\n    agent_labels=['solver', 'critic', 'reviser'],\n    turn_labels=['Turn 1', 'Turn 2', 'Turn 3'],\n    title='Agent x Turn Credit Attribution Heatmap'\n)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n1. **Monte Carlo Shapley:** Compare exact vs approximate (n=10, 50, 200 samples). When are they equivalent?\n2. **Coalition function:** Design a value function where critic has negative Shapley value. When would that happen?\n3. **Error cascade:** Create a trace where solver makes subtle error not caught by critic. What credit does critic receive?\n4. **AT-GRPO alpha:** Try alpha=0 (turn-only) vs 0.5 vs 1.0 (agent-only). Which stabilizes faster?\n5. **Extension:** Implement credit assignment on all 20 GSM8K problems and visualize distribution"
  }
 ]
}