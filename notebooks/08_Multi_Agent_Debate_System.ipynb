{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 08: Multi-Agent Debate & Mixture-of-Agents\n\n## Learning Objectives\n- Implement multi-agent debate (Du et al., 2023)\n- Implement Mixture-of-Agents (MoA) (Wang et al., 2024)\n- Compare: single agent vs debate vs MoA\n- Visualize convergence over debate rounds"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Multi-Agent Debate\n\nKey idea: agents argue and update based on others' responses.\n\n```\nRound 0: Agent1(Q), Agent2(Q), Agent3(Q)  \u2190 independent\nRound 1: Agent1(Q + A2_prev + A3_prev),   \u2190 sees others\n          Agent2(Q + A1_prev + A3_prev),\n          Agent3(Q + A1_prev + A2_prev)\nConverge when majority agree\n```\n\n## Mixture-of-Agents\n\n```\nLayer 1 (Proposers): Agent1(Q), Agent2(Q), Agent3(Q)  \u2190 diverse, parallel\nLayer 2 (Aggregator): Aggregator(Q + all_proposals)  \u2190 synthesis\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# !pip install torch transformers"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '..')\nfrom src.agents import SolverAgent\nfrom src.orchestration import DebateOrchestrator, MixtureOfAgents\nimport json, matplotlib.pyplot as plt\nprint('Ready!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Multi-Agent Debate"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "agents = [SolverAgent(agent_id=f'solver_{i}') for i in range(3)]\ndebate = DebateOrchestrator(agents, num_rounds=3, convergence_threshold=0.67)\nproblem = 'A train travels 60 km/h for 3 hours. How far does it go?'\nresult = debate.run(problem, ground_truth=180.0)\nprint('Debate Result:')\nprint(f\"  Final answer: {result['final_answer']}\")\nprint(f\"  Correct:      {result['correct']}\")\nprint(f\"  Rounds to converge: {result['rounds_to_converge']}\")\nprint(f\"  Agreement per round: {result['agreement_per_round']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Visualize Debate Convergence"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.evaluation.visualization import plot_debate_convergence\nfig = plot_debate_convergence(\n    result['agreement_per_round'],\n    convergence_threshold=0.67,\n    title='Debate Convergence: Train Distance Problem'\n)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Mixture-of-Agents"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "proposers = [SolverAgent(agent_id=f'proposer_{i}') for i in range(3)]\naggregator = SolverAgent(agent_id='aggregator')\nmoa = MixtureOfAgents(proposers, aggregator)\nresult_moa = moa.run(problem, ground_truth=180.0)\nprint('MoA Result:')\nprint(f\"  Final answer: {result_moa['final_answer']}\")\nprint(f\"  Correct:      {result_moa['correct']}\")\nprint('\\nProposer responses:')\nfor i, r in enumerate(result_moa['proposer_responses']):\n    print(f'  Proposer {i+1}: {r[:70]}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n1. **Debate rounds:** Try num_rounds=1, 2, 3, 5. When does accuracy plateau?\n2. **Convergence threshold:** Try 0.5, 0.67, 1.0 (unanimous). Trade-off speed vs quality?\n3. **MoA agents:** Try proposers=2, 3, 5. When does adding more agents stop helping?\n4. **Disagreement analysis:** When agents disagree, which is more often right?\n5. **Extension:** Implement a weighted vote (agents with higher past accuracy vote more)"
  }
 ]
}